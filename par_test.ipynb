{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19fdad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'robomimic_hdf5', 'exclude_images': True, 'num_demos': 300}\n",
      "(195800, 127) (195800, 14) (195800,) (195800, 127) (195800,)\n",
      "[INFO] N=195800, obs_dim=127, act_dim=14\n",
      "[INFO] rmin=0.0000, QMIN=0.0000\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m         q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m q\n\u001b[0;32m--> 130\u001b[0m critic \u001b[38;5;241m=\u001b[39m \u001b[43mCritic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ln\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_LN\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m target \u001b[38;5;241m=\u001b[39m Critic(obs_dim, act_dim, use_ln\u001b[38;5;241m=\u001b[39mUSE_LN)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    132\u001b[0m target\u001b[38;5;241m.\u001b[39mload_state_dict(critic\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m~/miniconda3/envs/qc/lib/python3.10/site-packages/torch/nn/modules/module.py:1371\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qc/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 930\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qc/lib/python3.10/site-packages/torch/nn/modules/module.py:957\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 957\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m~/miniconda3/envs/qc/lib/python3.10/site-packages/torch/nn/modules/module.py:1357\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1352\u001b[0m             device,\n\u001b[1;32m   1353\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1354\u001b[0m             non_blocking,\n\u001b[1;32m   1355\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1356\u001b[0m         )\n\u001b[0;32m-> 1357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# Feasible action bounds (per-dimension)\n",
    "# 예: 환경 action이 [-1, 1]^d 라면\n",
    "# chunk(flatten dH)인 경우도 동일하게 각 dim에 대해 [-1,1]이라고 두는게 보통 시작점\n",
    "ELL = None  # shape (act_dim,)\n",
    "UU  = None  # shape (act_dim,)\n",
    "\n",
    "# Guard bounds for infeasible sampling: L < ell, u < U\n",
    "# 논문에서 \"100~1000x boundary\"도 가능하지만, 실전에서는 우선 2~5배부터\n",
    "GUARD_SCALE = 3.0  # U = u*GUARD_SCALE, L = ell*GUARD_SCALE\n",
    "DELTA = 0.5        # infeasible sampling width beyond L/U\n",
    "\n",
    "GAMMA = 0.99\n",
    "C_REWARD = 10.0      # reward scaling factor (실험: 1 vs 10 vs 100)\n",
    "USE_LN = True       # LayerNorm on hidden layers\n",
    "ALPHA_PA = 1.0      # PA weight (0이면 PA 없음)\n",
    "\n",
    "# Training (옵션)\n",
    "DO_TRAIN = True\n",
    "STEPS = 20000\n",
    "BATCH = 256\n",
    "LR = 3e-4\n",
    "\n",
    "# If minimum reward unknown, use dataset min\n",
    "RMIN_FROM_DATA = True\n",
    "\n",
    "# ---------------------------\n",
    "# Load dataset\n",
    "# ---------------------------\n",
    "\n",
    "DATA_PATH = \"/home/robros/git/qc-flow-priority-sampling/robomimic/dataset/transport/mh/low_dim_v15.hdf5\"  \n",
    "obs, act, rew, next_obs, done, info = load_offline_dataset(\n",
    "    DATA_PATH,\n",
    "    robomimic_obs_keys=None,      # None이면 low-dim key 자동 선택\n",
    "    exclude_images=True           # 기본 True (이미지는 자동 제외)\n",
    ")\n",
    "\n",
    "print(info)\n",
    "print(obs.shape, act.shape, rew.shape, next_obs.shape, done.shape)\n",
    "N, obs_dim = obs.shape\n",
    "act_dim = act.shape[1]\n",
    "\n",
    "if ELL is None or UU is None:\n",
    "    # 가장 흔한 기본: [-1, 1]^dim\n",
    "    ELL = -np.ones((act_dim,), dtype=np.float32)\n",
    "    UU  =  np.ones((act_dim,), dtype=np.float32)\n",
    "\n",
    "L = ELL * GUARD_SCALE\n",
    "U = UU  * GUARD_SCALE\n",
    "\n",
    "rmin = float(rew.min()) if RMIN_FROM_DATA else -1.0\n",
    "QMIN = C_REWARD * rmin / (1.0 - GAMMA)\n",
    "\n",
    "print(f\"[INFO] N={N}, obs_dim={obs_dim}, act_dim={act_dim}\")\n",
    "print(f\"[INFO] rmin={rmin:.4f}, QMIN={QMIN:.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Simple replay sampler\n",
    "# ---------------------------\n",
    "def sample_batch(batch_size: int):\n",
    "    idx = np.random.randint(0, N, size=(batch_size,))\n",
    "    return (\n",
    "        torch.from_numpy(obs[idx]).to(DEVICE),\n",
    "        torch.from_numpy(act[idx]).to(DEVICE),\n",
    "        torch.from_numpy(rew[idx]).to(DEVICE),\n",
    "        torch.from_numpy(next_obs[idx]).to(DEVICE),\n",
    "        torch.from_numpy(done[idx]).to(DEVICE),\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# Infeasible sampler (box-out) : a in A_I\n",
    "# ---------------------------\n",
    "def sample_infeasible_actions(batch_size: int):\n",
    "    \"\"\"\n",
    "    Sample actions from A_I:\n",
    "      pick one dim k, push it to [U_k, U_k+DELTA) or (L_k-DELTA, L_k]\n",
    "      keep others within feasible [ELL, UU]\n",
    "    \"\"\"\n",
    "    a = np.random.uniform(ELL, UU, size=(batch_size, act_dim)).astype(np.float32)\n",
    "\n",
    "    ks = np.random.randint(0, act_dim, size=(batch_size,))\n",
    "    side = np.random.rand(batch_size) < 0.5\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        k = ks[i]\n",
    "        if side[i]:\n",
    "            a[i, k] = np.random.uniform(U[k], U[k] + DELTA)\n",
    "        else:\n",
    "            a[i, k] = np.random.uniform(L[k] - DELTA, L[k])\n",
    "    return torch.from_numpy(a).to(DEVICE)\n",
    "\n",
    "# ---------------------------\n",
    "# Critic network (ReLU MLP + optional LN)\n",
    "# ---------------------------\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden=256, use_ln=True):\n",
    "        super().__init__()\n",
    "        self.use_ln = use_ln\n",
    "        self.fc1 = nn.Linear(obs_dim + act_dim, hidden)\n",
    "        self.ln1 = nn.LayerNorm(hidden) if use_ln else nn.Identity()\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.ln2 = nn.LayerNorm(hidden) if use_ln else nn.Identity()\n",
    "        self.fc3 = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, s, a):\n",
    "        x = torch.cat([s, a], dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = F.relu(x)\n",
    "        q = self.fc3(x).squeeze(-1)\n",
    "        return q\n",
    "\n",
    "critic = Critic(obs_dim, act_dim, use_ln=USE_LN).to(DEVICE)\n",
    "target = Critic(obs_dim, act_dim, use_ln=USE_LN).to(DEVICE)\n",
    "target.load_state_dict(critic.state_dict())\n",
    "opt = torch.optim.Adam(critic.parameters(), lr=LR)\n",
    "\n",
    "# ---------------------------\n",
    "# (Optional) Training: offline SARSA-ish 1-step target with same action (minimal)\n",
    "# For quick diagnostic only: y = c*r + gamma*(1-done)*Q_target(s', a_next_from_dataset)\n",
    "# Here we use dataset next action by shifting index as a cheap proxy (or sample a' ~ behavior)\n",
    "# ---------------------------\n",
    "def soft_update(tgt, src, tau=0.005):\n",
    "    for p_t, p in zip(tgt.parameters(), src.parameters()):\n",
    "        p_t.data.mul_(1 - tau).add_(tau * p.data)\n",
    "\n",
    "if DO_TRAIN:\n",
    "    for step in range(1, STEPS + 1):\n",
    "        s, a, r, s2, d = sample_batch(BATCH)\n",
    "\n",
    "        # reward scaling\n",
    "        r_scaled = C_REWARD * r\n",
    "\n",
    "        # cheap \"behavior next action\": sample random batch action (proxy)\n",
    "        # (원하면: 같은 idx의 next action이 있으면 그걸 쓰세요)\n",
    "        a2 = sample_batch(BATCH)[1].detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q2 = target(s2, a2)\n",
    "            y = r_scaled + GAMMA * (1.0 - d) * q2\n",
    "\n",
    "        q = critic(s, a)\n",
    "        td_loss = F.mse_loss(q, y)\n",
    "\n",
    "        # PA loss: force Q(s, a_I) -> QMIN\n",
    "        if ALPHA_PA > 0:\n",
    "            aI = sample_infeasible_actions(BATCH)\n",
    "            qI = critic(s, aI)\n",
    "            pa_loss = F.mse_loss(qI, torch.full_like(qI, float(QMIN)))\n",
    "            loss = td_loss + ALPHA_PA * pa_loss\n",
    "        else:\n",
    "            pa_loss = torch.tensor(0.0, device=DEVICE)\n",
    "            loss = td_loss\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        soft_update(target, critic)\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            print(f\"[step {step}] td={td_loss.item():.4f} pa={pa_loss.item():.4f} total={loss.item():.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluation & Visualization\n",
    "# ---------------------------\n",
    "critic.eval()\n",
    "\n",
    "# Choose states for evaluation\n",
    "M = 1024\n",
    "idx = np.random.randint(0, N, size=(M,))\n",
    "S_eval = torch.from_numpy(obs[idx]).to(DEVICE)\n",
    "\n",
    "# Sample dataset actions + infeasible actions\n",
    "A_data = torch.from_numpy(act[idx]).to(DEVICE)\n",
    "A_inf  = sample_infeasible_actions(M)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Q_data = critic(S_eval, A_data).cpu().numpy()\n",
    "    Q_inf  = critic(S_eval, A_inf).cpu().numpy()\n",
    "\n",
    "# (A) Histogram: Q on dataset vs infeasible\n",
    "plt.figure()\n",
    "plt.hist(Q_data, bins=60, alpha=0.7, label=\"Q on dataset actions\")\n",
    "plt.hist(Q_inf,  bins=60, alpha=0.7, label=\"Q on infeasible actions\")\n",
    "plt.axvline(QMIN, linestyle=\"--\", label=\"Q_min\")\n",
    "plt.legend()\n",
    "plt.title(\"Q distribution: dataset vs infeasible\")\n",
    "plt.xlabel(\"Q\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "# (B) Scatter: action norm vs Q\n",
    "A_data_np = A_data.cpu().numpy()\n",
    "A_inf_np  = A_inf.cpu().numpy()\n",
    "norm_data = np.linalg.norm(A_data_np, axis=1) / (np.linalg.norm(UU) + 1e-8)\n",
    "norm_inf  = np.linalg.norm(A_inf_np,  axis=1) / (np.linalg.norm(UU * GUARD_SCALE) + 1e-8)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(norm_data, Q_data, s=10, alpha=0.6, label=\"dataset\")\n",
    "plt.scatter(norm_inf,  Q_inf,  s=10, alpha=0.6, label=\"infeasible\")\n",
    "plt.axhline(QMIN, linestyle=\"--\", label=\"Q_min\")\n",
    "plt.legend()\n",
    "plt.title(\"Action norm vs Q (should suppress infeasible)\")\n",
    "plt.xlabel(\"normalized action norm\")\n",
    "plt.ylabel(\"Q\")\n",
    "plt.show()\n",
    "\n",
    "# (C) 2D slice heatmap around a fixed state: vary two dims (i,j), keep others at a dataset action\n",
    "# Choose a single evaluation state/action anchor\n",
    "s0 = torch.from_numpy(obs[idx[0:1]]).to(DEVICE)\n",
    "a0 = torch.from_numpy(act[idx[0:1]]).to(DEVICE)  # anchor action\n",
    "i, j = 0, min(1, act_dim-1)  # choose two dims (change if needed)\n",
    "\n",
    "grid = 101\n",
    "x = np.linspace(L[i] - DELTA, U[i] + DELTA, grid).astype(np.float32)  # includes infeasible zone\n",
    "y = np.linspace(L[j] - DELTA, U[j] + DELTA, grid).astype(np.float32)\n",
    "\n",
    "A_grid = np.repeat(a0.cpu().numpy(), grid * grid, axis=0)\n",
    "A_grid[:, i] = np.tile(x, grid)\n",
    "A_grid[:, j] = np.repeat(y, grid)\n",
    "\n",
    "S_grid = np.repeat(s0.cpu().numpy(), grid * grid, axis=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Q_grid = critic(torch.from_numpy(S_grid).to(DEVICE),\n",
    "                    torch.from_numpy(A_grid).to(DEVICE)).cpu().numpy()\n",
    "Q_grid = Q_grid.reshape(grid, grid)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Q_grid, origin=\"lower\",\n",
    "           extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "           aspect=\"auto\")\n",
    "plt.colorbar(label=\"Q\")\n",
    "plt.title(f\"2D slice of Q(s,a): dims ({i},{j})\")\n",
    "plt.xlabel(f\"a[{i}]\")\n",
    "plt.ylabel(f\"a[{j}]\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e230928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
